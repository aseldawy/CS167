# Lab 10 - Vector Database

---

## Objectives

* Understand vector search and its applications in big data systems.
* Use Elasticsearch's kNN (k-Nearest Neighbors) search for semantic similarity.
* Implement semantic text search using vector embeddings.
* Compare vector similarity search with traditional full-text search.
* Analyze performance characteristics of vector search operations.

---

## Prerequisites

* Access to your CS167 remote machine
* Elasticsearch 7.3+ installed on CS167 machines (or you will install it)
* Setup the development environment as explained in [Lab 2](../Lab2/CS167-Lab2.md)
* Dataset files provided (download from course website):
  - `movie_reviews.csv` - 1000 movie reviews
  - `review_embeddings.json` - Pre-computed 384-dim vectors
  - `query_vector_0.json` - Sample query vector
  - `query_positive.json` - Positive review query
  - `query_negative.json` - Negative review query

---


## Lab Work(It's a individual lab)

### Part I: Project Setup (20 minutes) (In-home)

1. SSH into your CS167 machine:
    ```bash
    ssh cs167
    ```

2. Create a new Maven project:
    ```bash
    cd ~/cs167/workspace
    mvn archetype:generate \
        -DgroupId=edu.ucr.cs.cs167.[UCRNetID] \
        -DartifactId=[UCRNetID]_lab10 \
        -DarchetypeArtifactId=maven-archetype-quickstart \
        -DarchetypeVersion=1.4 \
        -DinteractiveMode=false
    ```

3. Update `pom.xml` with the following dependencies:
    ```xml
    <properties>
        <maven.compiler.source>11</maven.compiler.source>
        <maven.compiler.target>11</maven.compiler.target>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <elasticsearch.version>7.17.10</elasticsearch.version>
    </properties>

    <dependencies>
        <!-- Elasticsearch Java Client -->
        <dependency>
            <groupId>org.elasticsearch.client</groupId>
            <artifactId>elasticsearch-rest-high-level-client</artifactId>
            <version>${elasticsearch.version}</version>
        </dependency>
        
        <!-- JSON processing -->
        <dependency>
            <groupId>com.google.code.gson</groupId>
            <artifactId>gson</artifactId>
            <version>2.10.1</version>
        </dependency>
        
        <!-- Apache Commons CSV -->
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-csv</artifactId>
            <version>1.10.0</version>
        </dependency>
    </dependencies>
    ```

4. Compile to verify setup:
    ```bash
    cd ~/cs167/workspace/[UCRNetID]_lab10
    mvn clean compile
    ```

5. Download upload files to /data directory
    ```

---

### Part II: Elasticsearch Setup (20 minutes) (In-home)

1. Check if Elasticsearch is installed:
    ```bash
    curl -X GET "localhost:9200/"
    ```

2. If not installed, install Elasticsearch:
    ```bash
    # Download Elasticsearch
    cd ~/cs167
    wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.17.10-linux-x86_64.tar.gz
    tar -xzf elasticsearch-7.17.10-linux-x86_64.tar.gz
    
    # Start Elasticsearch
    cd elasticsearch-7.17.10
    ./bin/elasticsearch -d  # Run in background
    
    # Wait ~30 seconds for startup, then verify
    curl -X GET "localhost:9200/"
    ```

3. You should see a JSON response with cluster information.

---

### Part III: Code Framework (10 minutes) (In-Lab)

Create `VectorSearchApp.java` in `src/main/java/edu/ucr/cs/cs167/[UCRNetID]/`:

**Note:** This is the complete framework with all TODOs marked. You will implement each TODO in Part IV.

```java
package edu.ucr.cs.cs167.[UCRNetID];

import com.google.gson.Gson;
import com.google.gson.reflect.TypeToken;
import org.apache.commons.csv.*;
import org.apache.http.HttpHost;
import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
import org.elasticsearch.action.bulk.BulkRequest;
import org.elasticsearch.action.bulk.BulkResponse;
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.action.search.SearchRequest;
import org.elasticsearch.action.search.SearchResponse;
import org.elasticsearch.client.*;
import org.elasticsearch.client.indices.CreateIndexRequest;
import org.elasticsearch.client.indices.GetIndexRequest;
import org.elasticsearch.xcontent.XContentType;
import org.elasticsearch.index.query.QueryBuilders;
import org.elasticsearch.search.SearchHit;
import org.elasticsearch.search.builder.SearchSourceBuilder;

import java.io.*;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.*;

public class VectorSearchApp {
    
    private static final String INDEX_NAME = "movie_reviews";
    private static final int VECTOR_DIM = 384;
    private RestHighLevelClient client;
    
    public static void main(String[] args) {
        if (args.length < 2) {
            System.out.println("Usage: <es-host:port> <operation> [params...]");
            System.out.println("Operations:");
            System.out.println("  create    - Create index");
            System.out.println("  load <reviews.csv> <embeddings.json> - Load data");
            System.out.println("  search <query_text> <query_vector_file> - Vector search");
            System.out.println("  textsearch <query> - Full-text search");
            System.out.println("  stats     - Show index statistics");
            System.out.println("  benchmark <query_vector_file> <topK> <iterations> - Benchmark");
            System.exit(1);
        }
        
        String esHost = args[0];
        String operation = args[1];
        
        VectorSearchApp app = new VectorSearchApp();
        app.connect(esHost);
        
        try {
            switch (operation) {
                case "create":
                    app.createIndex();
                    break;
                case "load":
                    if (args.length < 4) {
                        System.out.println("Usage: load <reviews.csv> <embeddings.json>");
                        System.exit(1);
                    }
                    app.loadData(args[2], args[3]);
                    break;
                case "search":
                    if (args.length < 4) {
                        System.out.println("Usage: search <query_text> <query_vector_file>");
                        System.exit(1);
                    }
                    app.vectorSearch(args[2], args[3]);
                    break;
                case "textsearch":
                    if (args.length < 3) {
                        System.out.println("Usage: textsearch <query>");
                        System.exit(1);
                    }
                    app.textSearch(args[2]);
                    break;
                case "stats":
                    app.showStats();
                    break;
                case "benchmark":
                    if (args.length < 5) {
                        System.out.println("Usage: benchmark <query_vector_file> <topK> <iterations>");
                        System.exit(1);
                    }
                    app.benchmarkSearch(args[2], Integer.parseInt(args[3]), Integer.parseInt(args[4]));
                    break;
                default:
                    System.out.println("Unknown operation: " + operation);
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            app.close();
        }
    }
    
    // TODO A: Connect to Elasticsearch
    public void connect(String host) {
        // TODO: Parse host:port and create RestHighLevelClient
    }
    
    public void close() {
        // TODO: Close the client connection
    }
    
    // TODO B: Create index with dense_vector mapping
    public void createIndex() throws IOException {
        // TODO: Check if index exists, delete if necessary
        // TODO: Create index with mapping for dense_vector field
    }
    
    // TODO C: Load data from CSV and embeddings JSON
    public void loadData(String csvPath, String embeddingsPath) throws IOException {
        // TODO: Load embeddings from JSON
        // TODO: Read CSV and create bulk requests
        // TODO: Index documents with embeddings
    }
    
    // TODO D: Vector search with query embedding
    public void vectorSearch(String queryText, String queryVectorFile) throws IOException {
        // TODO: Load query vector
        // TODO: Create script_score query with cosineSimilarity
        // TODO: Execute search and display results
    }
    
    // TODO E: Text search for comparison
    public void textSearch(String query) throws IOException {
        // TODO: Create match query on review_text field
        // TODO: Execute and display results
    }
    
    // TODO F: Show statistics
    public void showStats() throws IOException {
        // TODO: Get document count and index information
    }
    
    // TODO G: Performance benchmark
    public void benchmarkSearch(String queryVectorFile, int topK, int iterations) 
            throws IOException {
        // TODO: Run vector search multiple times and measure average latency
    }
    
    private Map<String, List<Double>> loadEmbeddings(String path) throws IOException {
        Gson gson = new Gson();
        try (Reader reader = Files.newBufferedReader(Paths.get(path))) {
            return gson.fromJson(reader, new TypeToken<Map<String, List<Double>>>(){}.getType());
        }
    }
    
    private List<Float> loadQueryVector(String path) throws IOException {
        Gson gson = new Gson();
        try (Reader reader = Files.newBufferedReader(Paths.get(path))) {
            List<Double> doubleList = gson.fromJson(reader, new TypeToken<List<Double>>(){}.getType());
            List<Float> floatList = new ArrayList<>();
            for (Double d : doubleList) {
                floatList.add(d.floatValue());
            }
            return floatList;
        }
    }
    
    private String truncate(String text, int maxLength) {
        if (text == null) return "";
        if (text.length() <= maxLength) return text;
        return text.substring(0, maxLength) + "...";
    }
}
```

---

### Part IV: Implementation (90 minutes) (In-Lab)

Now implement each TODO step by step. Each section includes the TODO with hints and related question(s).

---

#### TODO A: Connect to Elasticsearch

**Task:** Implement the `connect()` and `close()` methods to establish and close connection to Elasticsearch.

```java
public void connect(String host) {
    try {
        // TODO: Parse host:port string (format: "localhost:9200")
        // Hint: Use String.split(":") to separate hostname and port
        
        // TODO: Create RestHighLevelClient
        // Hint: Use RestClient.builder(new HttpHost(hostname, port, "http"))
        
        System.out.println("Connected to Elasticsearch at " + hostname + ":" + port);
    } catch (Exception e) {
        System.err.println("Failed to connect: " + e.getMessage());
        throw new RuntimeException(e);
    }
}

public void close() {
    try {
        if (client != null) {
            // TODO: Close the client
            System.out.println("Connection closed");
        }
    } catch (IOException e) {
        System.err.println("Error closing connection: " + e.getMessage());
    }
}
```

**Question Q1:**
What is the purpose of using RestHighLevelClient instead of directly calling Elasticsearch REST API endpoints? What are the advantages?

---

#### TODO B: Create Index with Dense Vector Mapping

**Task:** Create an Elasticsearch index with proper mapping for storing movie reviews and their vector embeddings.

```java
public void createIndex() throws IOException {
    // Check if index exists
    GetIndexRequest getIndexRequest = new GetIndexRequest(INDEX_NAME);
    boolean exists = client.indices().exists(getIndexRequest, RequestOptions.DEFAULT);
    
    if (exists) {
        System.out.println("Index already exists. Deleting...");
        // TODO: Delete existing index
        // Hint: Use DeleteIndexRequest
    }
    
    // Create index with mappings
    CreateIndexRequest request = new CreateIndexRequest(INDEX_NAME);
    
    // TODO: Define mapping JSON string with these properties:
    //   - review_id: type "long"
    //   - review_text: type "text" with "english" analyzer
    //   - sentiment: type "keyword"
    //   - embedding: type "dense_vector" with dims=384
    // Hint: Use a multi-line string with proper JSON format
    
    // TODO: Set the mapping on the request
    // Hint: request.mapping(mappings, XContentType.JSON);
    
    // TODO: Create the index
    // Hint: client.indices().create(request, RequestOptions.DEFAULT);
    
    System.out.println("Index '" + INDEX_NAME + "' created successfully");
}
```

**Question Q2:**
Examine the index mapping you created. What is the purpose of the `dense_vector` field type? Why do we specify `dims=384`? What would happen if we tried to index a vector with a different dimensionality?

---

#### TODO C: Load Data from CSV and Embeddings

**Task:** Read movie reviews from CSV and their embeddings from JSON, then index them in Elasticsearch using bulk operations.

```java
public void loadData(String csvPath, String embeddingsPath) throws IOException {
    System.out.println("Loading data from " + csvPath);
    long startTime = System.currentTimeMillis();
    
    // Load embeddings from JSON (helper method provided)
    Map<String, List<Double>> embeddings = loadEmbeddings(embeddingsPath);
    System.out.println("Loaded " + embeddings.size() + " embeddings");
    
    // TODO: Create BulkRequest for batch indexing
    // Hint: BulkRequest bulkRequest = new BulkRequest();
    int count = 0;
    int batchSize = 100;
    
    // Read CSV file
    try (Reader reader = Files.newBufferedReader(Paths.get(csvPath))) {
        CSVParser csvParser = new CSVParser(reader, CSVFormat.DEFAULT
            .withFirstRecordAsHeader()
            .withIgnoreHeaderCase()
            .withTrim());
        
        for (CSVRecord record : csvParser) {
            String reviewId = record.get("review_id");
            String text = record.get("text");
            String sentiment = record.get("sentiment");
            
            // Get embedding for this review
            List<Double> embedding = embeddings.get(reviewId);
            if (embedding == null) {
                System.err.println("Warning: No embedding for review_id " + reviewId);
                continue;
            }
            
            // TODO: Create document Map with fields:
            //   - review_id (Long) - use Long.parseLong(reviewId)
            //   - review_text (String)
            //   - sentiment (String)
            //   - embedding (List<Double>)
            // Hint: Use HashMap<String, Object>
            
            // TODO: Create IndexRequest with the document
            // Hint: new IndexRequest(INDEX_NAME).id(reviewId).source(document)
            
            // TODO: Add IndexRequest to bulkRequest
            // Hint: bulkRequest.add(indexRequest)
            
            count++;
            
            // Execute bulk every batchSize documents
            if (count % batchSize == 0) {
                // TODO: Execute bulk request
                // Hint: client.bulk(bulkRequest, RequestOptions.DEFAULT)
                
                // TODO: Check for failures
                // Hint: if (bulkResponse.hasFailures()) { ... }
                
                // TODO: Create new BulkRequest for next batch
                
                System.out.println("Indexed " + count + " documents...");
            }
        }
        
        // TODO: Index remaining documents (if any)
        // Hint: Check if bulkRequest.numberOfActions() > 0
    }
    
    long endTime = System.currentTimeMillis();
    System.out.println("Successfully indexed " + count + " documents");
    System.out.println("Total time: " + (endTime - startTime) / 1000.0 + " seconds");
}
```

**Question Q3:**
Run the load command with your dataset. How long did it take to index 1000 documents? What is the benefit of using bulk indexing (batch_size=100) compared to indexing documents one by one? Estimate how much time you would save with bulk indexing.

---

#### TODO D: Vector Search with Query Embedding

**Task:** Implement semantic search using vector similarity (cosine similarity).

```java
public void vectorSearch(String queryText, String queryVectorFile) throws IOException {
    System.out.println("\n========================================");
    System.out.println("Vector Search Query: " + queryText);
    System.out.println("========================================");
    
    long startTime = System.currentTimeMillis();
    
    // Load query vector (helper method provided)
    List<Float> queryVector = loadQueryVector(queryVectorFile);
    
    // TODO: Convert List<Float> to float[] array
    // Hint: Create float array of size queryVector.size(), then copy elements in a loop
    
    // Create search request with script score query
    SearchRequest searchRequest = new SearchRequest(INDEX_NAME);
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    
    // TODO: Define script source for cosine similarity
    // Format: "cosineSimilarity(params.query_vector, 'embedding') + 1.0"
    // Note: +1.0 shifts range from [-1,1] to [0,2]
    
    // TODO: Create params Map with query_vector
    // Hint: Map<String, Object> params = new HashMap<>();
    //       params.put("query_vector", vectorArray);
    
    // TODO: Create scriptScoreQuery with the script
    // Hint: QueryBuilders.scriptScoreQuery(
    //         QueryBuilders.matchAllQuery(),
    //         new org.elasticsearch.script.Script(
    //           org.elasticsearch.script.ScriptType.INLINE,
    //           "painless",
    //           scriptSource,
    //           params
    //         )
    //       )
    
    sourceBuilder.size(5);
    searchRequest.source(sourceBuilder);
    
    // TODO: Execute search
    // Hint: SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
    
    // Display results
    int rank = 1;
    for (SearchHit hit : response.getHits().getHits()) {
        Map<String, Object> source = hit.getSourceAsMap();
        
        System.out.println("\nResult " + rank + ":");
        System.out.println("  Score: " + hit.getScore());
        System.out.println("  Review ID: " + source.get("review_id"));
        System.out.println("  Sentiment: " + source.get("sentiment"));
        System.out.println("  Text: " + truncate((String) source.get("review_text"), 200));
        
        rank++;
    }
    
    long endTime = System.currentTimeMillis();
    System.out.println("\nSearch completed in " + (endTime - startTime) + " milliseconds");
}
```

**Question Q4:**
Run vector search using different query vectors:
- Use `query_positive.json` with query text "excellent movie"
- Use `query_negative.json` with query text "terrible film"

For each query, report:
1. The top 5 results with their scores and sentiments
2. Do the results make semantic sense?
3. Are the returned reviews mostly positive or negative? Does this match the query sentiment?
4. Provide specific examples of interesting semantic matches (e.g., finding "fantastic" when searching for "excellent")

---

#### TODO E: Text Search for Comparison

**Task:** Implement traditional keyword-based full-text search for comparison with vector search.

```java
public void textSearch(String query) throws IOException {
    SearchRequest searchRequest = new SearchRequest(INDEX_NAME);
    SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
    
    // TODO: Create match query on review_text field
    // Hint: QueryBuilders.matchQuery("review_text", query)
    
    sourceBuilder.size(5);
    searchRequest.source(sourceBuilder);
    
    // TODO: Execute search
    // Hint: SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
    
    System.out.println("\n========================================");
    System.out.println("Text Search: " + query);
    System.out.println("========================================");
    
    int rank = 1;
    for (SearchHit hit : response.getHits().getHits()) {
        Map<String, Object> source = hit.getSourceAsMap();
        
        System.out.println("\nResult " + rank + ":");
        System.out.println("  Score: " + hit.getScore());
        System.out.println("  Review ID: " + source.get("review_id"));
        System.out.println("  Sentiment: " + source.get("sentiment"));
        System.out.println("  Text: " + truncate((String) source.get("review_text"), 200));
        
        rank++;
    }
}
```

**Question Q5:**
Compare vector search with text search using the same query (e.g., "excellent movie"):
1. What are the key differences in the results?
2. Which approach finds more semantically related content?
3. What are the score ranges for each method? Why are they different?
4. Give specific examples where vector search found relevant results that text search missed (or vice versa).

---

#### TODO F: Show Statistics

**Task:** Display index statistics including document count and configuration.

```java
public void showStats() throws IOException {
    // TODO: Create CountRequest and get document count
    // Hint: org.elasticsearch.client.core.CountRequest countRequest = 
    //         new org.elasticsearch.client.core.CountRequest(INDEX_NAME);
    //       org.elasticsearch.client.core.CountResponse countResponse = 
    //         client.count(countRequest, RequestOptions.DEFAULT);
    
    System.out.println("\n========================================");
    System.out.println("Index Statistics");
    System.out.println("========================================");
    System.out.println("  Index name: " + INDEX_NAME);
    // TODO: Print document count from countResponse
    System.out.println("  Vector dimension: " + VECTOR_DIM);
    
    // TODO: Get index settings (optional - for verification)
    // Hint: GetIndexRequest request = new GetIndexRequest(INDEX_NAME);
    //       client.indices().get(request, RequestOptions.DEFAULT);
    
    System.out.println("  Mappings configured: ✓");
}
```

---

#### TODO G: Performance Benchmark

**Task:** Measure search performance for different top-K values.

```java
public void benchmarkSearch(String queryVectorFile, int topK, int iterations) 
        throws IOException {
    System.out.println("\n========================================");
    System.out.println("Benchmark: Top-" + topK + " search");
    System.out.println("Iterations: " + iterations);
    System.out.println("========================================");
    
    List<Float> queryVector = loadQueryVector(queryVectorFile);
    
    long totalTime = 0;
    for (int i = 0; i < iterations; i++) {
        long start = System.currentTimeMillis();
        
        // TODO: Execute the same vector search as in TODO D
        // Copy the search logic but don't print results
        // Hint: Create SearchRequest, SearchSourceBuilder, convert vector to array,
        //       create script_score query, execute search
        
        long end = System.currentTimeMillis();
        totalTime += (end - start);
    }
    
    double avgTime = totalTime / (double) iterations;
    System.out.println("\nResults:");
    System.out.println("  Top-K: " + topK);
    System.out.println("  Average latency: " + String.format("%.2f", avgTime) + " ms");
    System.out.println("  Total time: " + totalTime + " ms");
}
```

**Question Q6:**
Run benchmarks for different Top-K values (5, 10, 20, 50) with 10 iterations each. Fill in the performance table:

| Top-K | Avg Latency (ms) | Dataset Size | Notes |
|-------|------------------|--------------|-------|
| 5     |                  | 1000 docs    |       |
| 10    |                  | 1000 docs    |       |
| 20    |                  | 1000 docs    |       |
| 50    |                  | 1000 docs    |       |

**Question Q7:**
Analyze the performance scaling:
1. How does search latency scale with the number of results requested (top-K)?
2. Is the scaling linear, sublinear, or superlinear?
3. Explain why this scaling behavior occurs (consider the HNSW algorithm and how Elasticsearch retrieves results).
4. At what point would the latency become unacceptable for a real-time application?

---

### Part V: Running the Application (20 minutes) (In-Lab)

#### Compile the Project
```bash
cd ~/cs167/workspace/[UCRNetID]_lab10
mvn clean package
```

#### Run Operations in Sequence

**1. Create Index:**
```bash
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 create"
```

**2. Load Data:**
```bash
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 load data/movie_reviews.csv data/review_embeddings.json"
```

**3. Show Statistics:**
```bash
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 stats"
```

**4. Vector Search (Positive Query):**
```bash
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 search 'excellent movie' data/query_positive.json"
```

**5. Vector Search (Negative Query):**
```bash
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 search 'terrible film' data/query_negative.json"
```

**6. Text Search (for comparison):**
```bash
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 textsearch 'excellent movie'"
```

**7. Benchmarks (for Q6-Q7):**
```bash
# Top-5
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 benchmark data/query_vector_0.json 5 10"

# Top-10
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 benchmark data/query_vector_0.json 10 10"

# Top-20
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 benchmark data/query_vector_0.json 20 10"

# Top-50
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 benchmark data/query_vector_0.json 50 10"
```

---

### Part VI: Submission (10 minutes)

1. Create `README.md` with answers to all questions (Q1-Q7).

2. Your README should include:
   - **Q1**: RestHighLevelClient advantages
   - **Q2**: Dense vector field explanation
   - **Q3**: Data loading performance analysis
   - **Q4**: Vector search results analysis (with examples)
   - **Q5**: Vector vs text search comparison (with examples)
   - **Q6**: Performance table (filled in)
   - **Q7**: Performance scaling analysis

3. Compile and create archive:
    ```bash
    cd ~/cs167/workspace/[UCRNetID]_lab10
    mvn clean package
    
    cd ~/cs167/workspace
    tar -czf [UCRNetID]_lab10.tar.gz \
        [UCRNetID]_lab10/src \
        [UCRNetID]_lab10/pom.xml \
        [UCRNetID]_lab10/README.md
    ```

---

## Rubric

| Component | Points | Description |
|-----------|--------|-------------|
| Q1-Q7 | 7 points | All questions answered with analysis (1 point each) |
| TODO A-G | 7 points | All code TODOs implemented correctly |
| Code Quality | 0.5 point | Clean code, proper error handling |
| Submission Format | 0.5 point | Correct archive structure, README included |
| **Total** | **15 points** | |

### Detailed Grading

**TODOs (7 points):**
- TODO A (Connect): 0.5 point
- TODO B (Create Index): 1.5 points
- TODO C (Load Data): 1.5 points
- TODO D (Vector Search): 1.5 points
- TODO E (Text Search): 0.5 point
- TODO F (Statistics): 0.5 point
- TODO G (Benchmark): 1 point

**Questions (7 points):**
- Q1: 0.5 point (conceptual understanding)
- Q2: 1 point (technical explanation)
- Q3: 0.5 point (performance observation)
- Q4: 1.5 points (detailed analysis with examples required)
- Q5: 1.5 points (comparison with specific examples required)
- Q6: 1 point (complete performance table)
- Q7: 1 point (scaling analysis with explanation)

---

## Troubleshooting

### Common Issues

**1. XContentType import error:**
```
Error: cannot find symbol class XContentType in org.elasticsearch.common.xcontent
```
**Solution:** Use the correct import:
```java
import org.elasticsearch.xcontent.XContentType;  // Not .common.xcontent
```

**2. Connection refused to Elasticsearch:**
```bash
# Check if ES is running
ps aux | grep elasticsearch
curl -X GET "localhost:9200/"

# Start if not running
cd ~/cs167/elasticsearch-7.17.10
./bin/elasticsearch -d
```

**3. Out of memory during data loading:**
If you encounter heap space errors, edit Elasticsearch JVM options:
```bash
vim ~/cs167/elasticsearch-7.17.10/config/jvm.options
# Set: -Xms512m and -Xmax512m
```

**4. Query vector file not found:**
Make sure you extracted the data archive in the data directory:
```bash
cd ~/cs167/workspace/[UCRNetID]_lab10/data
ls -lh
# Should see all 5 files
```

**5. Compilation errors:**
Common issues:
- Missing semicolons
- Incorrect variable types (e.g., using List instead of float[])
- Wrong method signatures
- Unmatched brackets

**6. Runtime errors:**
- Check that Elasticsearch is running
- Verify data files exist in the correct location
- Ensure CSV and JSON files are properly formatted
- Check index was created before loading data

---

## Optional Part: Generate Your Own Embeddings (Advanced)

If you want to experiment with your own dataset, you can generate embeddings using Python and the `sentence-transformers` library.

### Prerequisites
```bash
# Install sentence-transformers
pip install sentence-transformers pandas
```

### Step 1: Prepare Your CSV
Create a CSV file with at least these columns:
```csv
review_id,text,sentiment
0,"Your review text here",pos
1,"Another review",neg
```

### Step 2: Generate Embeddings

```python
# generate_embeddings.py
from sentence_transformers import SentenceTransformer
import pandas as pd
import json

# Load the model (same one used for provided data)
print("Loading model...")
model = SentenceTransformer('all-MiniLM-L6-v2')

# Read your CSV
print("Reading CSV...")
df = pd.read_csv('your_reviews.csv')

# Generate embeddings
print(f"Generating embeddings for {len(df)} reviews...")
embeddings = {}

for idx, row in df.iterrows():
    review_id = str(row['review_id'])
    text = row['text']
    
    # Generate embedding (384-dimensional vector)
    embedding = model.encode(text).tolist()
    embeddings[review_id] = embedding
    
    if (idx + 1) % 100 == 0:
        print(f"  Processed {idx + 1} reviews...")

# Save embeddings to JSON
print("Saving embeddings...")
with open('review_embeddings.json', 'w') as f:
    json.dump(embeddings, f)

print(f"✓ Generated {len(embeddings)} embeddings")
print(f"✓ Vector dimension: {len(embeddings['0'])}")
print(f"✓ Saved to review_embeddings.json")
```

### Step 3: Create Query Vectors

```python
# create_query_vectors.py
from sentence_transformers import SentenceTransformer
import json

model = SentenceTransformer('all-MiniLM-L6-v2')

# Define your queries
queries = {
    'query_positive.json': 'excellent wonderful fantastic movie great',
    'query_negative.json': 'terrible awful horrible bad worst',
    'query_neutral.json': 'movie film cinema watch'
}

# Generate and save query vectors
for filename, query_text in queries.items():
    embedding = model.encode(query_text).tolist()
    
    with open(filename, 'w') as f:
        json.dump(embedding, f)
    
    print(f"✓ Created {filename}")

print("\nYou can now use these query vectors with your VectorSearchApp!")
```

### Step 4: Use Your Data

```bash
# Copy your files to the data directory
cp your_reviews.csv ~/cs167/workspace/[UCRNetID]_lab10/data/movie_reviews.csv
cp review_embeddings.json ~/cs167/workspace/[UCRNetID]_lab10/data/
cp query_*.json ~/cs167/workspace/[UCRNetID]_lab10/data/

# Run the lab with your data
cd ~/cs167/workspace/[UCRNetID]_lab10
mvn exec:java -Dexec.mainClass="edu.ucr.cs.cs167.[UCRNetID].VectorSearchApp" \
  -Dexec.args="localhost:9200 load data/movie_reviews.csv data/review_embeddings.json"
```

